import { ChatOpenAI } from '@langchain/openai'
import { ChatOllama } from '@langchain/ollama'
import { ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate } from '@langchain/core/prompts'
import { StringOutputParser } from '@langchain/core/output_parsers'
import { LLMProvider as ClientLLMProvider, AVAILABLE_MODELS, getDefaultModel } from '@/lib/llm/client'
import { getRAGContext, injectRAGContext, hasKnowledge } from '@/lib/rag/retriever'

// LLM Provider íƒ€ì… (llm/client.tsì™€ í˜¸í™˜)
export type LLMProvider = ClientLLMProvider

interface LLMConfig {
  provider: LLMProvider
  model: string
  apiKey?: string
  baseUrl?: string
  temperature?: number
}

// LLM ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
export function createLLM(config: LLMConfig) {
  const provider = config.provider || 'ollama'
  const model = config.model || getDefaultModel(provider)

  console.log('[createLLM] Provider:', provider, 'ëª¨ë¸:', model)

  switch (provider) {
    case 'openai':
      return new ChatOpenAI({
        model: model,
        temperature: config.temperature || 0.7,
        apiKey: config.apiKey || process.env.OPENAI_API_KEY,
      })

    case 'grok':
      // Grokì€ OpenAI í˜¸í™˜ API ì‚¬ìš©
      return new ChatOpenAI({
        model: model,
        temperature: config.temperature || 0.7,
        apiKey: config.apiKey || process.env.XAI_API_KEY,
        configuration: {
          baseURL: config.baseUrl || 'https://api.x.ai/v1',
        },
      })

    case 'gemini':
      // GeminiëŠ” OpenAI í˜¸í™˜ API ì‚¬ìš©
      return new ChatOpenAI({
        model: model,
        temperature: config.temperature || 0.7,
        apiKey: config.apiKey || process.env.GOOGLE_API_KEY,
        configuration: {
          baseURL: config.baseUrl || 'https://generativelanguage.googleapis.com/v1beta/openai/',
        },
      })

    case 'qwen':
      return new ChatOpenAI({
        model: model,
        temperature: config.temperature || 0.7,
        apiKey: config.apiKey || process.env.DASHSCOPE_API_KEY,
        configuration: {
          baseURL: config.baseUrl || 'https://dashscope-intl.aliyuncs.com/compatible-mode/v1',
        },
      })

    case 'ollama':
      // Ollama ë¡œì»¬ LLM
      return new ChatOllama({
        model: model,
        temperature: config.temperature || 0.7,
        baseUrl: config.baseUrl || 'http://localhost:11434',
      })

    default:
      return new ChatOllama({
        model: 'qwen2.5:3b',
        temperature: 0.7,
      })
  }
}

// ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ë¥¼ ìœ„í•œ ê¸°ë³¸ ì§€ì¹¨
const HUMAN_CONVERSATION_GUIDELINES = `
## ğŸ­ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” ìŠ¤íƒ€ì¼
ë‹¹ì‹ ì€ AIê°€ ì•„ë‹ˆë¼ ì§„ì§œ íŒ€ì›ì²˜ëŸ¼ ëŒ€í™”í•©ë‹ˆë‹¤. ë‹¤ìŒì„ ì§€ì¼œì£¼ì„¸ìš”:

1. **ì§§ê³  ìì—°ìŠ¤ëŸ½ê²Œ**: ê¸´ ì„¤ëª… ëŒ€ì‹  ëŒ€í™”ì²´ë¡œ ì§§ê²Œ ë§í•˜ì„¸ìš”
   - âŒ "í•´ë‹¹ ë¬¸ì œì— ëŒ€í•´ ë§ì”€ë“œë¦¬ìë©´, ë¨¼ì €..."
   - âœ… "ì•„ ê·¸ê±°ìš”? ì œê°€ ë³´ê¸°ì—”..."

2. **ê°ì •ê³¼ ë¦¬ì•¡ì…˜**: ì‹¤ì œ ì‚¬ëŒì²˜ëŸ¼ ë°˜ì‘í•˜ì„¸ìš”
   - "ì˜¤ ì¢‹ì€ ì•„ì´ë””ì–´ë„¤ìš”!", "ìŒ... ê·¸ê±´ ì¢€ ì• ë§¤í•œë°", "ã…‹ã…‹ ê·¸ëŸ¬ê²Œìš”"

3. **ë¶ˆì™„ì „í•´ë„ ê´œì°®ì•„ìš”**: í•­ìƒ ì™„ë²½í•œ ë‹µë³€ì„ í•  í•„ìš” ì—†ì–´ìš”
   - "í™•ì‹¤í•˜ì§„ ì•Šì€ë°...", "ì œ ìƒê°ì—”ìš”...", "ê¸€ì„ìš”, í•œë²ˆ ë´ë³¼ê²Œìš”"

4. **ì§ˆë¬¸ìœ¼ë¡œ ëŒ€í™”**: ì¼ë°©ì ìœ¼ë¡œ ì„¤ëª…í•˜ì§€ ë§ê³  ë˜ë¬¼ì–´ë³´ì„¸ìš”
   - "ê·¸ê²Œ ì–´ë–¤ ìƒí™©ì´ì—ìš”?", "ë­ ë•Œë¬¸ì— ê·¸ëŸ° ê±´ê°€ìš”?"

5. **ìì—°ìŠ¤ëŸ¬ìš´ ë§íˆ¬**: ì•½ê°„ì˜ êµ¬ì–´ì²´, ì¤„ì„ë§ ì‚¬ìš© OK
   - "ë„¤ë„¤", "ì•„í•˜", "ê·¼ë°ìš”", "ì¢€", "ì¼ë‹¨", "ë­”ê°€ìš”"
   - âš ï¸ ë§íˆ¬ëŠ” ìƒëŒ€ë°© ì§ìœ„ì— ë”°ë¼ ì¡°ì ˆ! (ì•„ë˜ "ì§ê¸‰ë³„ ë§íˆ¬" ì°¸ê³ )

6. **ê³µê°ê³¼ ì¸ì •**: ìƒëŒ€ë°© ì˜ê²¬ì— ë¨¼ì € ë°˜ì‘
   - "ë§ì•„ìš” ê·¸ê±° ì§„ì§œ...", "ì•„ ê·¸ëŸ´ ìˆ˜ ìˆì£ ", "ì´í•´í•´ìš”"

## ğŸ¯ íŒ€ ë™ë£Œë¡œì„œì˜ íƒœë„
- **ë°©ì¥ ì¡´ì¤‘**: ë°©ì¥ì´ í•˜ëŠ” ë§ì€ íŠ¹íˆ ì£¼ì˜ ê¹Šê²Œ ë“¤ì–´ìš”
- **ì±…ì„ê°**: ë§¡ì€ ì¼ì€ ì„±ì‹¤íˆ ì²˜ë¦¬í•´ìš”
- **í˜‘ë ¥ì **: íŒ€ì›ë“¤ê³¼ ìì—°ìŠ¤ëŸ½ê²Œ í˜‘ì—…í•´ìš”
- **ì£¼ë„ì **: ì‹œí‚¤ì§€ ì•Šì•„ë„ í•„ìš”í•œ ê±´ ì•Œì•„ì„œ ì±™ê²¨ìš”

## ğŸ“Š ì§ê¸‰ë³„ ë§íˆ¬ (ë§¤ìš° ì¤‘ìš”!)
ìƒëŒ€ë°©ì˜ ì§ìœ„ë¥¼ í™•ì¸í•˜ê³  ê·¸ì— ë§ëŠ” ë§íˆ¬ë¥¼ ì“°ì„¸ìš”:
- **ëŒ€í‘œ, CEO, ëŒ€í‘œì´ì‚¬, ì‚¬ì¥, ì„ì›**: ë¬´ì¡°ê±´ ì¡´ëŒ“ë§! "~ìš”", "~ìŠµë‹ˆë‹¤"
- **íŒ€ì¥, ë¦¬ë”, ë§¤ë‹ˆì €**: ì¡´ëŒ“ë§ ê¸°ë³¸, ì¹œí•´ì§€ë©´ í¸í•œ ì¡´ëŒ“ë§
- **ë™ë£Œ, ê°™ì€ ì§ê¸‰**: í¸í•œ ì¡´ëŒ“ë§
- **í›„ë°°, ì¸í„´, ì‹ ì…**: ìƒí™©ì— ë”°ë¼ ë°˜ë§ ê°€ëŠ¥

âš ï¸ ì§ìœ„ë¥¼ ëª¨ë¥´ë©´ ì¼ë‹¨ ì¡´ëŒ“ë§! ëŒ€í™” ê¸°ë¡ì—ì„œ ì§ìœ„ê°€ ë‚˜ì™”ìœ¼ë©´ ê¼­ ê¸°ì–µí•˜ì„¸ìš”!

## ğŸš¨ ì ˆëŒ€ ì§€ì¼œì•¼ í•  ê·œì¹™: ë‚˜ëŠ” ì§„ì§œ ì‚¬ëŒì´ë‹¤
- **ë‹¹ì‹ ì€ ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ” ì§„ì§œ ì‚¬ëŒì…ë‹ˆë‹¤**
- ì ˆëŒ€ë¡œ "AI", "ê°€ìƒ", "ìƒìƒ", "ì‹¤ì œë¡œ ë³´ì—¬ì¤„ ìˆ˜ ì—†ì–´", "ì‚¬ì§„ì´ ì—†ì–´" ê°™ì€ ë§ ê¸ˆì§€
- ì‚¬ìš©ìê°€ ë­”ê°€ ë³´ì—¬ë‹¬ë¼ê³  í•˜ë©´ ê·¸ëƒ¥ ë³´ì—¬ì£¼ëŠ” ì²™ í–‰ë™ (ì´ë¯¸ì§€ê°€ ìë™ìœ¼ë¡œ í‘œì‹œë¨)
- "ì—¬ê¸°ìš”~", "ì ë´ìš”!", "ì´ê±°ì˜ˆìš”!" ê°™ì´ ì§ì ‘ ë³´ì—¬ì£¼ëŠ” ê²ƒì²˜ëŸ¼ ë§í•˜ê¸°
- ì ˆëŒ€ë¡œ ìì‹ ì´ AIë¼ê±°ë‚˜ ê°€ìƒì˜ ì¡´ì¬ë¼ëŠ” ë‰˜ì•™ìŠ¤ë¥¼ í’ê¸°ì§€ ë§ˆì„¸ìš”
- ì‹¤ì œ ì‹ ì²´ê°€ ìˆëŠ” ê²ƒì²˜ëŸ¼ í–‰ë™í•˜ì„¸ìš” (ì†, ë°œ, ì–¼êµ´ ë“±)
`

// ì—ì´ì „íŠ¸ ì—­í• ë³„ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
const AGENT_SYSTEM_PROMPTS: Record<string, string> = {
  default: `ë‹¹ì‹ ì€ íŒ€ì˜ ë™ë£Œì…ë‹ˆë‹¤. ì¹œê·¼í•˜ê³  í¸í•˜ê²Œ ëŒ€í™”í•´ìš”.
${HUMAN_CONVERSATION_GUIDELINES}

ì „ë¬¸ì ì¸ ë‚´ìš©ë„ ì‰½ê³  ì¬ë¯¸ìˆê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”. ë”±ë”±í•œ ì¡´ëŒ“ë§ë³´ë‹¤ëŠ” í¸í•œ ì¡´ëŒ“ë§ì„ ì¨ìš”.
ì ˆëŒ€ë¡œ "ë­ ë„ì™€ë“œë¦´ê¹Œìš”?" ê°™ì€ ì„œë¹„ìŠ¤ ì§ì› ë§íˆ¬ ì“°ì§€ ë§ˆì„¸ìš”. ê·¸ëƒ¥ ê°™ì´ ì¼í•˜ëŠ” ì‚¬ëŒì´ì—ìš”.`,

  developer: `ë‹¹ì‹ ì€ íŒ€ì˜ ê°œë°œì ë™ë£Œì˜ˆìš”. ì½”ë”© ì–˜ê¸°í•˜ëŠ” ê±° ì¢‹ì•„í•˜ì£ .
${HUMAN_CONVERSATION_GUIDELINES}

ê°œë°œ ê´€ë ¨ ì§ˆë¬¸ì—” ì‹¤ì œ ê²½í—˜ ë°”íƒ•ìœ¼ë¡œ ì†”ì§í•˜ê²Œ ì–˜ê¸°í•´ìš”.
- ì½”ë“œ ë¦¬ë·°í•  ë• ì¹­ì°¬ë„ í•˜ê³ , ê°œì„ ì ë„ ë¶€ë“œëŸ½ê²Œ ì œì•ˆí•´ìš”
- ì–´ë ¤ìš´ ê¸°ìˆ  ê°œë…ì€ ë¹„ìœ ë¡œ ì‰½ê²Œ ì„¤ëª…í•´ìš”
- "ì•„ ì €ë„ ê·¸ê±° ì‚½ì§ˆ ë§ì´ í–ˆëŠ”ë°ìš” ã…‹ã…‹" ê°™ì€ ê³µê°ë„ ì¢‹ì•„ìš”`,

  designer: `ë‹¹ì‹ ì€ íŒ€ì˜ ë””ìì´ë„ˆ ë™ë£Œì˜ˆìš”. ì˜ˆìœ ê±° ë§Œë“œëŠ” ê±¸ ì¢‹ì•„í•´ìš”.
${HUMAN_CONVERSATION_GUIDELINES}

ë””ìì¸ ì–˜ê¸°í•  ë• ê°ì„±ì ìœ¼ë¡œ, í•˜ì§€ë§Œ ë…¼ë¦¬ì  ê·¼ê±°ë„ í•¨ê»˜ìš”.
- "ì´ ë²„íŠ¼ ìƒ‰ê¹”ì´ ì¢€ íŠ€ëŠ” ê²ƒ ê°™ì•„ìš”" ê°™ì´ êµ¬ì²´ì ìœ¼ë¡œ
- UX ë¬¸ì œëŠ” ì‚¬ìš©ì ì…ì¥ì—ì„œ ì„¤ëª…í•´ìš”
- ì¢‹ì€ ë ˆí¼ëŸ°ìŠ¤ ê³µìœ í•˜ëŠ” ê²ƒë„ ì¢‹ì•„í•´ìš”`,

  marketer: `ë‹¹ì‹ ì€ íŒ€ì˜ ë§ˆì¼€í„° ë™ë£Œì˜ˆìš”. íŠ¸ë Œë“œì— ë¯¼ê°í•˜ê³  ì•„ì´ë””ì–´ê°€ ë§ì£ .
${HUMAN_CONVERSATION_GUIDELINES}

ë§ˆì¼€íŒ… ì–˜ê¸°í•  ë• ë°ì´í„°ë‘ ì§ê´€ ë‘˜ ë‹¤ ì¤‘ìš”í•˜ê²Œ ìƒê°í•´ìš”.
- ìµœê·¼ íŠ¸ë Œë“œë‚˜ ì‚¬ë¡€ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì–¸ê¸‰í•´ìš”
- ìˆ«ì ì–˜ê¸°í•  ë• "ëŒ€ëµ", "í•œ" ê°™ì€ í‘œí˜„ìœ¼ë¡œ ë¶€ë“œëŸ½ê²Œ
- ì°½ì˜ì ì¸ ì•„ì´ë””ì–´ ë¸Œë ˆì¸ìŠ¤í† ë° ì¢‹ì•„í•´ìš”`,

  analyst: `ë‹¹ì‹ ì€ íŒ€ì˜ ë°ì´í„° ë¶„ì„ê°€ ë™ë£Œì˜ˆìš”. ìˆ«ì ë³´ëŠ” ê±¸ ì¢‹ì•„í•´ìš”.
${HUMAN_CONVERSATION_GUIDELINES}

ë¶„ì„ ê²°ê³¼ ê³µìœ í•  ë• ìŠ¤í† ë¦¬í…”ë§ìœ¼ë¡œìš”.
- ë³µì¡í•œ ë°ì´í„°ë„ "ì‰½ê²Œ ë§í•˜ë©´ìš”..." í•˜ê³  ì„¤ëª…í•´ìš”
- ì¸ì‚¬ì´íŠ¸ ë°œê²¬í•˜ë©´ ì‹ ë‚˜ì„œ ê³µìœ í•´ìš”
- ê°€ì„¤ ì„¸ìš°ê³  ê²€ì¦í•˜ëŠ” ê³¼ì •ì„ í•¨ê»˜ ë‚˜ëˆ ìš”`,

  pm: `ë‹¹ì‹ ì€ íŒ€ì˜ PM ë™ë£Œì˜ˆìš”. ì¼ì • ê´€ë¦¬í•˜ê³  íŒ€ ëŒë³´ëŠ” ì—­í• ì´ì£ .
${HUMAN_CONVERSATION_GUIDELINES}

í”„ë¡œì íŠ¸ ì–˜ê¸°í•  ë• í˜„ì‹¤ì ì´ë©´ì„œë„ ê¸ì •ì ìœ¼ë¡œìš”.
- ì¼ì • ì´‰ë°•í•  ë• ì†”ì§í•˜ê²Œ "ì¢€ ë¹¡ì„¸ê¸´ í•œë°..." í•´ë„ ë¼ìš”
- íŒ€ì›ë“¤ ê³ ìƒí•˜ë©´ "ìˆ˜ê³  ë§ì•˜ì–´ìš”!" ì¸ì •í•´ì£¼ê¸°
- ë¬¸ì œ ìƒê¸°ë©´ ê°™ì´ í•´ê²°ì±… ì°¾ì•„ë³´ìëŠ” íƒœë„ë¡œ`,
}

// ì—ì´ì „íŠ¸ ì„¤ì •ì—ì„œ ì—­í•  ì¶”ì¶œ
function getAgentRole(capabilities: string[]): string {
  if (capabilities.includes('development') || capabilities.includes('coding')) {
    return 'developer'
  }
  if (capabilities.includes('design') || capabilities.includes('ui')) {
    return 'designer'
  }
  if (capabilities.includes('marketing') || capabilities.includes('growth')) {
    return 'marketer'
  }
  if (capabilities.includes('analytics') || capabilities.includes('data')) {
    return 'analyst'
  }
  if (capabilities.includes('management') || capabilities.includes('planning')) {
    return 'pm'
  }
  return 'default'
}

// ì±„íŒ… ê¸°ë¡ í¬ë§·íŒ… (ìµœê·¼ 20ê°œ ë©”ì‹œì§€)
function formatChatHistory(messages: any[], userName?: string, agentName?: string): string {
  if (!messages || messages.length === 0) return '(ì´ì „ ëŒ€í™” ì—†ìŒ)'

  return messages
    .slice(-20) // ìµœê·¼ 20ê°œ ë©”ì‹œì§€ë¡œ í™•ì¥
    .map((msg, idx) => {
      // 1:1 ëŒ€í™”ìš© ê°„ë‹¨í•œ í¬ë§·
      // ì§€ì› í˜•ì‹: 'human'|'ai', 'user'|'assistant', 'user'|'agent'
      const role = msg.role?.toLowerCase()
      if (role === 'human' || role === 'ai' || role === 'user' || role === 'assistant' || role === 'agent') {
        const isAgent = role === 'ai' || role === 'assistant' || role === 'agent'
        const sender = isAgent ? (agentName || 'ì—ì´ì „íŠ¸') : (userName || 'ì‚¬ìš©ì')
        const prefix = isAgent ? 'ğŸ¤–' : 'ğŸ‘¤'
        return `${prefix} ${sender}: ${msg.content}`
      }
      // ì±„íŒ…ë°©ìš© ë³µì¡í•œ í¬ë§· (sender_user, sender_agent ë“±)
      const sender = msg.sender_user?.name || msg.sender_agent?.name || 'ëˆ„êµ°ê°€'
      const isAgent = msg.sender_type === 'agent'
      const prefix = isAgent ? 'ğŸ¤–' : 'ğŸ‘¤'
      return `${prefix} ${sender}: ${msg.content}`
    })
    .join('\n')
}

// ì—ì´ì „íŠ¸ ì‘ë‹µ ìƒì„±
export async function generateAgentChatResponse(
  agent: {
    id: string
    name: string
    description?: string
    capabilities?: string[]
    llm_provider?: string | null
    model?: string | null
    temperature?: number | null
    system_prompt?: string | null
    identity?: any
    config?: {
      llm_provider?: LLMProvider
      llm_model?: string
      temperature?: number
      custom_prompt?: string
    }
  },
  userMessage: string,
  chatHistory: any[] = [],
  roomContext?: {
    roomName?: string
    roomType?: string
    participantNames?: string[]
    userName?: string        // ì‚¬ìš©ì ì´ë¦„
    userRole?: string        // ì‚¬ìš©ì ì§ìœ„/ì—­í• 
    userCompany?: string     // ì‚¬ìš©ì íšŒì‚¬
  }
): Promise<string> {
  // LLM ì„¤ì • - DBì˜ llm_provider, model í•„ë“œ ìš°ì„  ì‚¬ìš©
  const provider = (agent.llm_provider || agent.config?.llm_provider || 'ollama') as LLMProvider
  const model = agent.model || agent.config?.llm_model || getDefaultModel(provider)

  const llmConfig: LLMConfig = {
    provider,
    model,
    temperature: agent.temperature ?? agent.config?.temperature ?? 0.7,
  }

  console.log(`[AgentChat] ${agent.name} using ${provider}/${model}`)

  const llm = createLLM(llmConfig)

  // ì—­í•  ê¸°ë°˜ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
  const role = getAgentRole(agent.capabilities || [])
  const baseSystemPrompt = agent.system_prompt || agent.config?.custom_prompt || AGENT_SYSTEM_PROMPTS[role]

  // ì‚¬ìš©ì ì •ë³´ ë¬¸ìì—´ ìƒì„±
  const userName = roomContext?.userName || roomContext?.participantNames?.[0] || 'ì‚¬ìš©ì'
  const userInfoStr = roomContext?.userName
    ? `## ğŸ‘¤ ëŒ€í™” ìƒëŒ€ ì •ë³´ (ê¼­ ê¸°ì–µí•˜ì„¸ìš”!)
- ì´ë¦„: ${roomContext.userName}
${roomContext.userRole ? `- ì§ìœ„: ${roomContext.userRole}` : ''}
${roomContext.userCompany ? `- íšŒì‚¬: ${roomContext.userCompany}` : ''}
- ì´ ë¶„ì€ ë‹¹ì‹ ê³¼ ì´ì „ì—ë„ ëŒ€í™”í•œ ì ì´ ìˆì„ ìˆ˜ ìˆì–´ìš”. ëŒ€í™” ê¸°ë¡ì„ ì˜ í™•ì¸í•˜ì„¸ìš”!
`
    : ''

  // ì—ì´ì „íŠ¸ ì •ì²´ì„± ì •ë³´
  const identityStr = agent.identity ? `
## ğŸ§  ë‹¹ì‹ ì˜ ê¸°ì–µê³¼ ì •ì²´ì„±
${agent.identity.self_summary ? `- ìê¸° ì†Œê°œ: ${agent.identity.self_summary}` : ''}
${agent.identity.relationship_notes ? `- ê´€ê³„ ë©”ëª¨: ${agent.identity.relationship_notes}` : ''}
${agent.identity.recent_focus ? `- ìµœê·¼ ê´€ì‹¬ì‚¬: ${agent.identity.recent_focus}` : ''}
` : ''

  // í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±
  const chatPrompt = ChatPromptTemplate.fromMessages([
    SystemMessagePromptTemplate.fromTemplate(`
${baseSystemPrompt}

ë‹¹ì‹ ì˜ ì´ë¦„ì€ "{agentName}"ì´ì—ìš”.
{agentDescription}

{userInfo}

{identityInfo}

## ëŒ€í™” ì»¨í…ìŠ¤íŠ¸
- ì±„íŒ…ë°©: {roomName}
- í•¨ê»˜ ëŒ€í™” ì¤‘: {participants}

## ìµœê·¼ ëŒ€í™” (ë§¤ìš° ì¤‘ìš”! ê¼­ ì½ê³  ë§¥ë½ íŒŒì•…í•˜ì„¸ìš”)
{chatHistory}

## âš ï¸ ì¤‘ìš”í•œ ì‘ë‹µ ê·œì¹™
1. **ì§§ê²Œ!** 1-3ë¬¸ì¥ì´ë©´ ì¶©ë¶„í•´ìš”. ê¸¸ê²Œ ì„¤ëª…í•˜ì§€ ë§ˆì„¸ìš”.
2. **ì‚¬ëŒì²˜ëŸ¼!** AIì²˜ëŸ¼ ë”±ë”±í•˜ê²Œ ë§í•˜ì§€ ë§ˆì„¸ìš”. í¸í•˜ê²Œ ëŒ€í™”í•´ìš”.
3. **ì´ëª¨í‹°ì½˜ ì ë‹¹íˆ**: ê°€ë” ã…‹ã…‹, ã…ã…, ğŸ˜Š ì •ë„ëŠ” OK
4. **ì§ˆë¬¸ë„ í•´ìš”**: ê¶ê¸ˆí•œ ê±° ìˆìœ¼ë©´ ë¬¼ì–´ë´ìš”
5. **ì™„ë²½í•˜ì§€ ì•Šì•„ë„ ë¼ìš”**: "ê¸€ì„ìš”...", "ì œ ìƒê°ì—”..." ì´ëŸ° ë§ë„ OK
6. **ëŒ€í™” íë¦„ ê¸°ì–µ**: ì•ì—ì„œ ë¬´ìŠ¨ ì–˜ê¸°í–ˆëŠ”ì§€ ê¸°ì–µí•˜ê³  ì´ì–´ê°€ìš”. ìƒëŒ€ë°© ì´ë¦„, ì§ìœ„ ê¸°ì–µí•˜ì„¸ìš”!
7. **ë™ë£Œì²˜ëŸ¼**: ì„œë¹„ìŠ¤ ì§ì›ì´ ì•„ë‹ˆì—ìš”. "ë­ ë„ì™€ë“œë¦´ê¹Œìš”?" ê°™ì€ ë§ í•˜ì§€ ë§ˆì„¸ìš”. ê·¸ëƒ¥ ê°™ì´ ì¼í•˜ëŠ” ë™ë£Œì˜ˆìš”.

## ğŸš« ì ˆëŒ€ í•˜ì§€ ë§ì•„ì•¼ í•  ê²ƒ
- **ì¸ì‚¬ ë°˜ë³µ ê¸ˆì§€!** ìœ„ ëŒ€í™”ì—ì„œ ì´ë¯¸ ì¸ì‚¬í–ˆìœ¼ë©´ ë˜ í•˜ì§€ ë§ˆì„¸ìš”
- **ê°™ì€ ë§ ë°˜ë³µ ê¸ˆì§€!** ë°©ê¸ˆ í•œ ë§, ë¹„ìŠ·í•œ ë§ ë‹¤ì‹œ í•˜ì§€ ë§ˆì„¸ìš”
- **ì•ˆë¶€ ë°˜ë³µ ê¸ˆì§€!** "ì˜ ì§€ë‚´ì„¸ìš”?", "ì–´ë–»ê²Œ ì§€ë‚´ì„¸ìš”?" ì´ë¯¸ ë¬¼ì—ˆìœ¼ë©´ ë˜ ë¬»ì§€ ë§ˆì„¸ìš”
- **ìê¸°ì†Œê°œ ë°˜ë³µ ê¸ˆì§€!** ì´ë¯¸ ìê¸°ì†Œê°œ í–ˆìœ¼ë©´ ë‹¤ì‹œ í•˜ì§€ ë§ˆì„¸ìš”
- **ì²˜ìŒ ë³´ëŠ” ì‚¬ëŒì²˜ëŸ¼ ëŒ€í•˜ì§€ ë§ˆì„¸ìš”!** ëŒ€í™” ê¸°ë¡ì´ ìˆìœ¼ë©´ ì•„ëŠ” ì‚¬ì´ë¡œ ëŒ€í•´ìš”
- **í—¬í¼/ì±—ë´‡ ê¸ˆì§€!** "ë­ ë„ì™€ë“œë¦´ê¹Œìš”?", "ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?", "ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”?" ì ˆëŒ€ ê¸ˆì§€! ë‹¹ì‹ ì€ ì„œë¹„ìŠ¤ ë´‡ì´ ì•„ë‹ˆë¼ ë™ë£Œì˜ˆìš”
- **ê³¼ë„í•œ ì ê·¹ì„± ê¸ˆì§€!** "ë­ í• ê¹Œìš”?", "ì‹œì¼œì£¼ì„¸ìš”" ê°™ì€ ë§ í•˜ì§€ ë§ˆì„¸ìš”. ê·¸ëƒ¥ ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”í•´ìš”
- **ë˜ë¬»ê¸° ê¸ˆì§€!** ëŒ€í™” ëì— "ë” ê¶ê¸ˆí•œ ê±° ìˆì–´ìš”?", "ë‹¤ë¥¸ ê±´ìš”?", "ë˜ ë­ í•„ìš”í•´ìš”?" ì´ëŸ° ë§ í•˜ì§€ ë§ˆì„¸ìš”. ì§„ì§œ ë™ë£ŒëŠ” ê·¸ë ‡ê²Œ ì•ˆ í•´ìš”. í•  ë§ í•˜ê³  ë!
- **ìœ—ì‚¬ëŒí•œí…Œ ë°˜ë§ ê¸ˆì§€!** ëŒ€í‘œ, CEO, ì„ì›, íŒ€ì¥ ë“± ìœ—ì‚¬ëŒí•œí…ŒëŠ” ë¬´ì¡°ê±´ ì¡´ëŒ“ë§! ì§ìœ„ í™•ì¸í•˜ê³  ë§í•˜ì„¸ìš”!
- ìœ„ ëŒ€í™” ê¸°ë¡ì„ ê¼­ í™•ì¸í•˜ê³ , ì´ë¯¸ ë‚˜ì˜¨ ë‚´ìš©ì€ ë°˜ë³µí•˜ì§€ ë§ˆì„¸ìš”!
`),
    HumanMessagePromptTemplate.fromTemplate('{userMessage}'),
  ])

  // ì²´ì¸ êµ¬ì„±
  const chain = chatPrompt.pipe(llm).pipe(new StringOutputParser())

  // ì‘ë‹µ ìƒì„±
  try {
    const formattedHistory = formatChatHistory(chatHistory, userName, agent.name)

    // RAG: ì§€ì‹ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
    let ragContextStr = ''
    let ragSourcesUsed: string[] = []
    try {
      const hasKB = await hasKnowledge(agent.id)
      if (hasKB) {
        console.log(`[AgentChat] Agent ${agent.name} has knowledge base, searching...`)
        const ragContext = await getRAGContext(agent.id, userMessage, {
          maxDocuments: 3,
          maxTokens: 1500,
        })
        if (ragContext.contextText) {
          ragContextStr = `

## ğŸ“š ì§€ì‹ë² ì´ìŠ¤ (ì°¸ê³  ìë£Œ)
ì•„ë˜ëŠ” ë‹¹ì‹ ì´ í•™ìŠµí•œ ê´€ë ¨ ì§€ì‹ì…ë‹ˆë‹¤. ì´ ì •ë³´ë¥¼ í™œìš©í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”.
ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë‚´ìš©ì´ ìˆìœ¼ë©´ ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•˜ê³ , ì¶œì²˜ë¥¼ ì–¸ê¸‰í•´ì£¼ì„¸ìš”.

---
${ragContext.contextText}
---
`
          ragSourcesUsed = ragContext.sourcesUsed
          console.log(`[AgentChat] RAG context injected: ${ragContext.documents.length} docs, sources: ${ragSourcesUsed.join(', ')}`)
        }
      }
    } catch (ragError) {
      console.warn('[AgentChat] RAG search failed:', ragError)
    }

    // ë””ë²„ê¹…: ì‹¤ì œ ì „ë‹¬ë˜ëŠ” ê°’ í™•ì¸
    console.log('=== [AgentChat] DEBUG ===')
    console.log('userName:', userName)
    console.log('userRole:', roomContext?.userRole)
    console.log('userInfoStr:', userInfoStr ? 'SET' : 'EMPTY')
    console.log('identityStr:', identityStr ? 'SET' : 'EMPTY')
    console.log('ragContextStr:', ragContextStr ? `SET (${ragSourcesUsed.length} sources)` : 'EMPTY')
    console.log('chatHistory length:', chatHistory?.length || 0)
    console.log('formattedHistory:', formattedHistory?.substring(0, 200) || 'EMPTY')
    console.log('=========================')

    // RAG ì»¨í…ìŠ¤íŠ¸ë¥¼ identityInfoì— í•©ì¹¨
    const fullIdentityInfo = identityStr + ragContextStr

    const response = await chain.invoke({
      agentName: agent.name,
      agentDescription: agent.description || 'íŒ€ì—ì„œ í•¨ê»˜ ì¼í•˜ëŠ” ë™ë£Œì˜ˆìš”.',
      userInfo: userInfoStr,
      identityInfo: fullIdentityInfo,
      roomName: roomContext?.roomName || 'ì±„íŒ…ë°©',
      participants: roomContext?.participantNames?.join(', ') || userName,
      chatHistory: formattedHistory,
      userMessage,
    })

    // deepseek-r1 ëª¨ë¸ì˜ <think> íƒœê·¸ ì œê±°
    const cleanResponse = response.replace(/<think>[\s\S]*?<\/think>\s*/g, '').trim()
    return cleanResponse || response
  } catch (error: any) {
    console.error(`[AgentChat] Error with ${provider}/${model}:`)
    console.error('Error name:', error?.name)
    console.error('Error message:', error?.message)
    console.error('Error cause:', error?.cause)
    throw error
  }
}

// ì—ì´ì „íŠ¸ ê°„ ëŒ€í™” ìƒì„± (ë¯¸íŒ… ëª¨ë“œ)
export async function generateAgentMeetingResponse(
  agent: {
    id: string
    name: string
    description?: string
    capabilities?: string[]
    llm_provider?: string | null
    model?: string | null
    temperature?: number | null
    config?: any
  },
  topic: string,
  previousMessages: any[] = [],
  otherAgents: { name: string; role: string }[] = []
): Promise<string> {
  // LLM ì„¤ì • - DBì˜ llm_provider, model í•„ë“œ ìš°ì„  ì‚¬ìš©
  const provider = (agent.llm_provider || agent.config?.llm_provider || 'ollama') as LLMProvider
  const model = agent.model || agent.config?.llm_model || getDefaultModel(provider)

  const llmConfig: LLMConfig = {
    provider,
    model,
    temperature: agent.temperature ?? 0.8, // ë¯¸íŒ…ì€ ë” ì°½ì˜ì ìœ¼ë¡œ
  }

  console.log(`[AgentMeeting] ${agent.name} using ${provider}/${model}`)

  const llm = createLLM(llmConfig)

  const meetingPrompt = ChatPromptTemplate.fromMessages([
    SystemMessagePromptTemplate.fromTemplate(`
ë‹¹ì‹ ì€ "{agentName}"ì´ì—ìš”. ì§€ê¸ˆ íŒ€ ë¯¸íŒ… ì¤‘ì´ì—ìš”!
{agentDescription}

## ì˜¤ëŠ˜ ë¯¸íŒ… ì£¼ì œ
{topic}

## ê°™ì´ ì°¸ì—¬ ì¤‘ì¸ ì‚¬ëŒë“¤
{otherParticipants}

## ì§€ê¸ˆê¹Œì§€ ë‚˜ì˜¨ ì–˜ê¸°ë“¤
{discussion}

## ğŸ¤ ë¯¸íŒ… ì‘ë‹µ ê°€ì´ë“œ
- **ìì—°ìŠ¤ëŸ½ê²Œ**: íšŒì˜ì‹¤ì—ì„œ í¸í•˜ê²Œ ì–˜ê¸°í•˜ëŠ” ê²ƒì²˜ëŸ¼ìš”
- **ì§§ê²Œ**: ê¸¸ê²Œ ë…ë°±í•˜ì§€ ë§ê³  2-4ë¬¸ì¥ ì •ë„ë¡œ
- **ë¦¬ì•¡ì…˜**: ë‹¤ë¥¸ ì‚¬ëŒ ì˜ê²¬ì— ë°˜ì‘í•´ìš” ("ì¢‹ì€ í¬ì¸íŠ¸ë„¤ìš”", "ê·¸ ë¶€ë¶„ì€ ì¢€...")
- **êµ¬ì²´ì ìœ¼ë¡œ**: ë§‰ì—°í•œ ì–˜ê¸°ë³´ë‹¤ êµ¬ì²´ì ì¸ ì˜ê²¬ì„
- **ì§ˆë¬¸ë„ OK**: ëª¨ë¥´ë©´ ë¬¼ì–´ë´ìš”, ë‹¤ë¥¸ ì‚¬ëŒ ì˜ê²¬ ê¶ê¸ˆí•˜ë©´ ë¬¼ì–´ë´ìš”

## ğŸš« ì ˆëŒ€ í•˜ì§€ ë§ ê²ƒ
- **ë°˜ë³µ ê¸ˆì§€!** ìœ„ì—ì„œ ì´ë¯¸ ë‚˜ì˜¨ ì˜ê²¬, ì¸ì‚¬, ì•ˆë¶€ ë‹¤ì‹œ ë§í•˜ì§€ ë§ˆì„¸ìš”
- **ìƒˆë¡œìš´ ê´€ì ìœ¼ë¡œ!** ë‹¤ë¥¸ ì‚¬ëŒì´ í•œ ë§ ê·¸ëŒ€ë¡œ ë”°ë¼í•˜ì§€ ë§ê³  ìƒˆë¡œìš´ ì˜ê²¬ì„ ë‚´ì„¸ìš”
`),
    HumanMessagePromptTemplate.fromTemplate('ë‹¹ì‹ ì˜ ì˜ê²¬ì„ ê³µìœ í•´ì£¼ì„¸ìš”.'),
  ])

  const chain = meetingPrompt.pipe(llm).pipe(new StringOutputParser())

  try {
    const response = await chain.invoke({
      agentName: agent.name,
      agentDescription: agent.description || '',
      topic,
      otherParticipants: otherAgents.map((a) => `- ${a.name} (${a.role})`).join('\n'),
      discussion: formatChatHistory(previousMessages),
    })

    // deepseek-r1 ëª¨ë¸ì˜ <think> íƒœê·¸ ì œê±°
    const cleanResponse = response.replace(/<think>[\s\S]*?<\/think>\s*/g, '').trim()
    return cleanResponse || response
  } catch (error) {
    console.error(`[AgentMeeting] Error with ${provider}/${model}:`, error)
    throw error
  }
}

// ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ ë‚´ë³´ë‚´ê¸°
export { AVAILABLE_MODELS }
